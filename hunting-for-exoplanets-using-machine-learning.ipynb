{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1995,"sourceType":"datasetVersion","datasetId":1074}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Hunting for exoplanets using Machine Learning**\n*  **[Use machine learning to hunt for exoplanets](https://www.youtube.com/watch?v=y1k2jc3YTeg&list=PL7HQvd_RTCc3Vope7dkx4pggrH5f-uvZe)**.\n\n* Method used for hunting exoplanets: **[Transit Photometry](https://www.planetary.org/articles/down-in-front-the-transit-photometry-method)**\n\n* Dataset used: **[Kepler Space Telescope Dataset](https://www.kaggle.com/datasets/keplersmachines/kepler-labelled-time-series-data)**","metadata":{}},{"cell_type":"code","source":"# Import required libraries\n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:19.109225Z","iopub.execute_input":"2025-09-23T10:56:19.109680Z","iopub.status.idle":"2025-09-23T10:56:20.153825Z","shell.execute_reply.started":"2025-09-23T10:56:19.109654Z","shell.execute_reply":"2025-09-23T10:56:20.152953Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Analysing the dataset ##","metadata":{}},{"cell_type":"code","source":"# Read training dataset (CSV file) into a dataframe\n\ntrain_df = pd.read_csv(\"/kaggle/input/kepler-labelled-time-series-data/exoTrain.csv\")\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:20.155579Z","iopub.execute_input":"2025-09-23T10:56:20.156423Z","iopub.status.idle":"2025-09-23T10:56:24.373661Z","shell.execute_reply.started":"2025-09-23T10:56:20.156400Z","shell.execute_reply":"2025-09-23T10:56:24.372877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Shape of the training dataframe\n\ntrain_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:24.374456Z","iopub.execute_input":"2025-09-23T10:56:24.374666Z","iopub.status.idle":"2025-09-23T10:56:24.380548Z","shell.execute_reply.started":"2025-09-23T10:56:24.374650Z","shell.execute_reply":"2025-09-23T10:56:24.379625Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Check for missing values ##","metadata":{}},{"cell_type":"code","source":"# Display the rows with null values in the dataframe\n\ntrain_df[train_df.isnull().any(axis = 1)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:24.381497Z","iopub.execute_input":"2025-09-23T10:56:24.381727Z","iopub.status.idle":"2025-09-23T10:56:24.446481Z","shell.execute_reply.started":"2025-09-23T10:56:24.381710Z","shell.execute_reply":"2025-09-23T10:56:24.445708Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# We can visualize null values using a heatmap as well\n# Display null values in training dataframe\n# In this case, it'll return a blank plot as there are no missing values\n\nsns.heatmap(train_df.isnull())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:24.448512Z","iopub.execute_input":"2025-09-23T10:56:24.448760Z","iopub.status.idle":"2025-09-23T10:56:46.960473Z","shell.execute_reply.started":"2025-09-23T10:56:24.448739Z","shell.execute_reply":"2025-09-23T10:56:46.959581Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Decoding the labels in the dataset ##","metadata":{}},{"cell_type":"code","source":"# Check the number of labels in the train dataframe\n\ntrain_df['LABEL'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:46.961537Z","iopub.execute_input":"2025-09-23T10:56:46.961938Z","iopub.status.idle":"2025-09-23T10:56:46.968635Z","shell.execute_reply.started":"2025-09-23T10:56:46.961901Z","shell.execute_reply":"2025-09-23T10:56:46.967886Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract indexes of stars with exoplanets\n\ntrain_df[train_df['LABEL'] == 2].index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:46.969458Z","iopub.execute_input":"2025-09-23T10:56:46.969775Z","iopub.status.idle":"2025-09-23T10:56:46.994531Z","shell.execute_reply.started":"2025-09-23T10:56:46.969750Z","shell.execute_reply":"2025-09-23T10:56:46.993493Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* Rows 0 to 36 only are have label 2. This indicates only 37 stars have exoplanets in the train data.\n* The distribution of labels can also be visualized using countplot.","metadata":{}},{"cell_type":"code","source":"# Visualize distribution of both labels using countplot\n\nplt.figure(figsize = (3, 5))\nax = sns.countplot(x = 'LABEL', data = train_df)\nax.bar_label(ax.containers[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:46.995595Z","iopub.execute_input":"2025-09-23T10:56:46.996360Z","iopub.status.idle":"2025-09-23T10:56:47.132803Z","shell.execute_reply.started":"2025-09-23T10:56:46.996291Z","shell.execute_reply":"2025-09-23T10:56:47.131925Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* The train data is highly imbalanced as of now. We will work on both balanced and imbalanced data and compare the results.","metadata":{}},{"cell_type":"markdown","source":"## Replacing the labels ##\nReplace the labels for ease of working:\n\nStars with exoplanets: 2 -> 1\nStars without exoplanets: 1 -> 0","metadata":{}},{"cell_type":"code","source":"#Replacing the labels 2 and 1 with 1 and 0 respectively\n\ntrain_df = train_df.replace({\"LABEL\" : {2 : 1, 1: 0}})\ntrain_df.LABEL.unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:47.133803Z","iopub.execute_input":"2025-09-23T10:56:47.134033Z","iopub.status.idle":"2025-09-23T10:56:47.187236Z","shell.execute_reply.started":"2025-09-23T10:56:47.134015Z","shell.execute_reply":"2025-09-23T10:56:47.186402Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualizing the light curves in the data ##\n\nWhen an exoplanet passes between the telescope and the star, the flux value of the star decreases, which causes a dip in the light curve of the star. In other words, when we plot the graph of the flux values of a particular star, and if the light curve follows a particular pattern where the flux initially decreases, remains constant and then increases over time, this can hint at the star being a candidate with an exoplanet. ","metadata":{}},{"cell_type":"code","source":"# Drop the label column as we do not want to plot it in the curve\n\nplot_df = train_df.drop(['LABEL'], axis = 1)\nplot_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:47.188041Z","iopub.execute_input":"2025-09-23T10:56:47.188248Z","iopub.status.idle":"2025-09-23T10:56:47.255228Z","shell.execute_reply.started":"2025-09-23T10:56:47.188233Z","shell.execute_reply":"2025-09-23T10:56:47.254444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the light curve for a random star - here we plot for the 3rd star from the plot dataframe\n\ntime = range(1, 3198) # X - axis will hold the time periods staring from 1 to 3197\nflux_values = plot_df.iloc[3, :].values # Y - axis will hold the range of flux or brightness values for the star\nplt.figure(figsize = (15, 5))\nplt.plot(time, flux_values, linewidth = 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:59:28.349290Z","iopub.execute_input":"2025-09-23T10:59:28.349633Z","iopub.status.idle":"2025-09-23T10:59:28.571786Z","shell.execute_reply.started":"2025-09-23T10:59:28.349613Z","shell.execute_reply":"2025-09-23T10:59:28.570959Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can try to plot for multiple stars. We can observe that if a plot has multiple dips, then this could possibly be a multiplanetary system where the star is being orbited by more than one exoplanet. If the plot has no dips and almost follows a straight line, this could mean the star has no exoplanet(s) orbiting it.","metadata":{}},{"cell_type":"markdown","source":"Here, for few stars (like star 2998), we can observe that some flux values are extremely high that lie out of range. These high flux values act as extreme outliers that can be problematic for the machine learning model we use further to classify the stars.","metadata":{}},{"cell_type":"markdown","source":"## Handling outliers ##\nWe first visualize the outliers using boxplot","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (20, 9))\nfor i in range(1, 4):\n    plt.subplot(1, 4, i)\n    sns.boxplot(data = train_df, x = 'LABEL', y = 'FLUX.' + str(i))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:47.462177Z","iopub.execute_input":"2025-09-23T10:56:47.462431Z","iopub.status.idle":"2025-09-23T10:56:47.899688Z","shell.execute_reply.started":"2025-09-23T10:56:47.462412Z","shell.execute_reply":"2025-09-23T10:56:47.898859Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"By observing the dataset, we can infer that any flux values above 0.25 x 10â¶ are extreme outliers. We just drop these outliers.","metadata":{}},{"cell_type":"code","source":"# Dropping outliers\n\ntrain_df.drop(train_df[train_df['FLUX.2'] > 0.25e6].index, axis = 0, inplace = True)\nsns.boxplot(data = train_df, x = 'LABEL', y = 'FLUX.' + str(np.random.randint(1000)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:47.900702Z","iopub.execute_input":"2025-09-23T10:56:47.900956Z","iopub.status.idle":"2025-09-23T10:56:48.098001Z","shell.execute_reply.started":"2025-09-23T10:56:47.900938Z","shell.execute_reply":"2025-09-23T10:56:48.097150Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## The K - Nearest Neighbours Algorithm ##\n* Here, we use the KNN algorithm for classifying the data.\n* Although, KNN is sensitive to outliers and imbalanced data, its performance is shown to be better than other classification algorithms for this dataset.\n* Below are the steps to classify a new data point for a pre - determined value of K\n  1. Determine the value of K.\n  2. Use Euclidean distance to compute the distance between the new data point and all the other existing data points.\n  3. Choose the K data points that are nearest to the new data point.\n  4. Among these K points, pick the class that the majority of points are classified into.\n  5. Assign this class to the new data point.","metadata":{}},{"cell_type":"markdown","source":"## Implementing KNN ##\nWe first implement KNN on imbalanced data.","metadata":{}},{"cell_type":"code","source":"# We first extract the independent (x) and dependent (y) features from train dataframe\n# Here, our independent features are the flux values and the dependent feature is the label\n\nx = train_df.drop(['LABEL'], axis = 1)\ny = train_df.LABEL\nx, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:48.101236Z","iopub.execute_input":"2025-09-23T10:56:48.101522Z","iopub.status.idle":"2025-09-23T10:56:48.159721Z","shell.execute_reply.started":"2025-09-23T10:56:48.101502Z","shell.execute_reply":"2025-09-23T10:56:48.159021Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split dependent and independent features into train and test sets\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:48.160455Z","iopub.execute_input":"2025-09-23T10:56:48.160666Z","iopub.status.idle":"2025-09-23T10:56:48.322516Z","shell.execute_reply.started":"2025-09-23T10:56:48.160650Z","shell.execute_reply":"2025-09-23T10:56:48.321572Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Scaling ##\nThe flux values do not lie in a particular range in this dataset. They are varying between different values for each star. So we use feature scaling to scale the flux values","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train_sc = sc.fit_transform(x_train)\nx_test_sc = sc.transform(x_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:48.323467Z","iopub.execute_input":"2025-09-23T10:56:48.323860Z","iopub.status.idle":"2025-09-23T10:56:48.585397Z","shell.execute_reply.started":"2025-09-23T10:56:48.323842Z","shell.execute_reply":"2025-09-23T10:56:48.584619Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Modelling ##","metadata":{}},{"cell_type":"code","source":"# Fit the KNN classifier model on the scaled train data\nfrom sklearn.neighbors import KNeighborsClassifier as KNC\n\n# Choosing k = 5\nknn_classifier = KNC(n_neighbors = 1, metric = 'minkowski', p = 2)\n\n# Fitting the model\nknn_classifier.fit(x_train_sc, y_train)\n\n# Predict the labels for the scaled test set\ny_pred = knn_classifier.predict(x_test_sc)\n\n# Results\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, auc\n\nprint(\"Validation accuracy of KNN: \", accuracy_score(y_test, y_pred))\nprint()\nprint(\"Classification report: \\n\", classification_report(y_test, y_pred))\n\n# Confusion matrix\nplt.figure(figsize = (15,11))\nplt.subplots_adjust(wspace = 0.3)\nplt.suptitle(\"KNN Performance before handling the imbalance in data\", color = 'b', weight = 'bold')\nplt.subplot(221)\nsns.heatmap(confusion_matrix(y_test, y_pred), annot = True, cmap = \"Set2\", fmt = \"d\", linewidths = 3, cbar = False, xticklabels = ['Non - exoplanet', 'Exoplanet'], yticklabels = ['Non - exoplanet', 'Exoplanet'], square = True)\nplt.xlabel(\"Actual Labels\", fontsize = 15, weight = 'bold', color = 'tab:pink')\nplt.ylabel(\"Predicted Labels\", fontsize = 15, weight = 'bold', color = 'tab:pink')\nplt.title(\"Confusion Matrix\", fontsize = 20, color = 'm')\n\n# ROC Curve and Area under the curve\npredicting_probabilities = knn_classifier.predict_proba(x_test_sc)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, predicting_probabilities)\nplt.subplot(222)\nplt.plot(fpr, tpr, label = (\"AUC: \", auc(fpr, tpr)), color = 'g')\nplt.plot([1,0], [1,0], \"k--\")\nplt.legend()\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC - Curve and Area under the curve\", fontsize = 20, color = 'm')\nplt.show()\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:48.586288Z","iopub.execute_input":"2025-09-23T10:56:48.586622Z","iopub.status.idle":"2025-09-23T10:56:50.365069Z","shell.execute_reply.started":"2025-09-23T10:56:48.586595Z","shell.execute_reply":"2025-09-23T10:56:50.364071Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The classification report shows that the metrics precision, recall and F1 - score are all 0 for label 1, i.e., for stars with exoplanets. This is due to the high imbalance in data, as stars without exoplanets are way higher than stars with exoplanets. This imbalance has caused the KNN model to bias and predict towards stars without exoplanets. To handle this, we first balance the data and fit the model over the balanced data.","metadata":{}},{"cell_type":"markdown","source":"## Handling the imbalance in the data ##\nWe use RandomOverSampler for handling the imbalance in data. RandomOverSampler over - samples by duplicating some of the original samples from the minority class.","metadata":{}},{"cell_type":"markdown","source":"In my case, there was incompatibility with sklearn and imblearn versions. Hence, in the next two cells, I'm clearing the cache and installing the compatible versions. You would need to restart the kernel after installing the new versions.","metadata":{}},{"cell_type":"code","source":"# Clear Python cache\nimport sys\nif 'imblearn' in sys.modules:\n    del sys.modules['imblearn']\nif 'sklearn' in sys.modules:\n    del sys.modules['sklearn']\n\n# Force reimport\nimport importlib\nimportlib.invalidate_caches()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:50.366197Z","iopub.execute_input":"2025-09-23T10:56:50.366765Z","iopub.status.idle":"2025-09-23T10:56:50.372027Z","shell.execute_reply.started":"2025-09-23T10:56:50.366731Z","shell.execute_reply":"2025-09-23T10:56:50.371142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --no-deps scikit-learn==1.4.0 --force-reinstall --quiet\n!pip install --no-deps imbalanced-learn==0.12.0 --force-reinstall --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:50.372960Z","iopub.execute_input":"2025-09-23T10:56:50.373279Z","iopub.status.idle":"2025-09-23T10:56:57.306057Z","shell.execute_reply.started":"2025-09-23T10:56:50.373252Z","shell.execute_reply":"2025-09-23T10:56:57.304769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\n\nros = RandomOverSampler()\nx_ros, y_ros = ros.fit_resample(x, y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:57.307628Z","iopub.execute_input":"2025-09-23T10:56:57.308003Z","iopub.status.idle":"2025-09-23T10:56:58.279196Z","shell.execute_reply.started":"2025-09-23T10:56:57.307965Z","shell.execute_reply":"2025-09-23T10:56:58.278298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_ros.value_counts().plot(kind = 'bar', title = 'After applying RandomOverSampler')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:58.280355Z","iopub.execute_input":"2025-09-23T10:56:58.280724Z","iopub.status.idle":"2025-09-23T10:56:58.469591Z","shell.execute_reply.started":"2025-09-23T10:56:58.280705Z","shell.execute_reply":"2025-09-23T10:56:58.468769Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's compare and visualize imbalanced and balanced data","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nprint(f\"Before ROS: {Counter(y)}\\nAfter ROS: {Counter(y_ros)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:58.470510Z","iopub.execute_input":"2025-09-23T10:56:58.470733Z","iopub.status.idle":"2025-09-23T10:56:58.478193Z","shell.execute_reply.started":"2025-09-23T10:56:58.470716Z","shell.execute_reply":"2025-09-23T10:56:58.477444Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Initially, the count of class 0 was 5050. One entry is missing as it was an outlier and it was dropped.\nAfter applying ROS, both classes 0 and 1 have 5049 entries. In order to balance the data, to the initial 37 class 1 entries, 5012 additional (duplicate) entries were added. This also increased the size of the dataset.","metadata":{}},{"cell_type":"code","source":"# Initial size of imbalanced dataset\nprint(len(y))\n\n# Size of dataset after balancing\nprint(len(y_ros))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:58.479108Z","iopub.execute_input":"2025-09-23T10:56:58.479445Z","iopub.status.idle":"2025-09-23T10:56:58.497063Z","shell.execute_reply.started":"2025-09-23T10:56:58.479419Z","shell.execute_reply":"2025-09-23T10:56:58.496220Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Splitting balanced data into train and test set, scaling the data and data modelling ##","metadata":{}},{"cell_type":"code","source":"# Split dependent and independent features into train and test sets\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_ros, y_ros, test_size = 0.3, random_state = 0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:58.497905Z","iopub.execute_input":"2025-09-23T10:56:58.498186Z","iopub.status.idle":"2025-09-23T10:56:59.023064Z","shell.execute_reply.started":"2025-09-23T10:56:58.498160Z","shell.execute_reply":"2025-09-23T10:56:59.022358Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train_sc = sc.fit_transform(x_train)\nx_test_sc = sc.transform(x_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:59.023979Z","iopub.execute_input":"2025-09-23T10:56:59.024638Z","iopub.status.idle":"2025-09-23T10:56:59.808554Z","shell.execute_reply.started":"2025-09-23T10:56:59.024607Z","shell.execute_reply":"2025-09-23T10:56:59.807525Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Choosing optimal K value ##","metadata":{}},{"cell_type":"raw","source":"The value of K is the hyperparameter for the KNN model. Its value highly influences model prediction. Choosing the right value can be tricky. K is usually set to 5 in practice, but model performance can definitely be improved by choosing the optimum value depending on the dataset. One possibility for choosing the right value would be training the model for a range of values, evaluating it and choosing the best value.\n\nHere, we train the model and analyze the error rate for each value of K. We then pick the value with the least error rate. To compute the error rate for each K, we take the mean of those predicted and actual values where they don't match.\n","metadata":{}},{"cell_type":"code","source":"err_rate = []\n\nfor k in range(1,11):\n    knn_clasfr = KNC(n_neighbors = k)\n    knn_clasfr.fit(x_train_sc, y_train)\n    pred = knn_clasfr.predict(x_test_sc)\n    err_rate.append(np.mean(pred != y_test))\n\narg, val = err_rate.index(min(err_rate)), min(err_rate)\n\nplt.figure(figsize = (5,5))\nplt.plot(range(1, 11), err_rate, 'co--', markersize = 8)\nplt.plot(arg+1, val, marker = 'o', markersize = 8, markerfacecolor = 'r', markeredgecolor = 'g')\nplt.title(\"Error rate wrt K values with minimum K marked\")\nplt.ylabel(\"Error Rate\")\nplt.xlabel(\"K values\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:56:59.809596Z","iopub.execute_input":"2025-09-23T10:56:59.809875Z","iopub.status.idle":"2025-09-23T10:57:26.879695Z","shell.execute_reply.started":"2025-09-23T10:56:59.809856Z","shell.execute_reply":"2025-09-23T10:57:26.878737Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fit the KNN classifier model on the scaled train data\nfrom sklearn.neighbors import KNeighborsClassifier as KNC\n\n# Choosing k = 5\nknn_classifier = KNC(n_neighbors = 1, metric = 'minkowski', p = 2)\n\n# Fitting the model\nknn_classifier.fit(x_train_sc, y_train)\n\n# Predict the labels for the scaled test set\ny_pred = knn_classifier.predict(x_test_sc)\n\n# Results\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, auc\n\nprint(\"Validation accuracy of KNN: \", accuracy_score(y_test, y_pred))\nprint()\nprint(\"Classification report: \\n\", classification_report(y_test, y_pred))\n\n# Confusion matrix\nplt.figure(figsize = (15,11))\nplt.subplots_adjust(wspace = 0.3)\nplt.suptitle(\"KNN Performance before handling the imbalance in data\", color = 'b', weight = 'bold')\nplt.subplot(221)\nsns.heatmap(confusion_matrix(y_test, y_pred), annot = True, cmap = \"Set2\", fmt = \"d\", linewidths = 3, cbar = False, xticklabels = ['Non - exoplanet', 'Exoplanet'], yticklabels = ['Non - exoplanet', 'Exoplanet'], square = True)\nplt.xlabel(\"Actual Labels\", fontsize = 15, weight = 'bold', color = 'tab:pink')\nplt.ylabel(\"Predicted Labels\", fontsize = 15, weight = 'bold', color = 'tab:pink')\nplt.title(\"Confusion Matrix\", fontsize = 20, color = 'm')\n\n# ROC Curve and Area under the curve\npredicting_probabilities = knn_classifier.predict_proba(x_test_sc)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, predicting_probabilities)\nplt.subplot(222)\nplt.plot(fpr, tpr, label = (\"AUC: \", auc(fpr, tpr)), color = 'g')\nplt.plot([1,0], [1,0], \"k--\")\nplt.legend()\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC - Curve and Area under the curve\", fontsize = 20, color = 'm')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:57:26.880622Z","iopub.execute_input":"2025-09-23T10:57:26.880919Z","iopub.status.idle":"2025-09-23T10:57:32.378117Z","shell.execute_reply.started":"2025-09-23T10:57:26.880898Z","shell.execute_reply":"2025-09-23T10:57:32.377153Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Testing the model on the test set (unseen data) ##","metadata":{}},{"cell_type":"code","source":"# Read test dataset (CSV file) into a dataframe\n\ntest_df = pd.read_csv(\"/kaggle/input/kepler-labelled-time-series-data/exoTest.csv\")\ntest_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:57:32.379288Z","iopub.execute_input":"2025-09-23T10:57:32.379659Z","iopub.status.idle":"2025-09-23T10:57:32.932993Z","shell.execute_reply.started":"2025-09-23T10:57:32.379637Z","shell.execute_reply":"2025-09-23T10:57:32.932163Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:57:32.933817Z","iopub.execute_input":"2025-09-23T10:57:32.934080Z","iopub.status.idle":"2025-09-23T10:57:32.939606Z","shell.execute_reply.started":"2025-09-23T10:57:32.934061Z","shell.execute_reply":"2025-09-23T10:57:32.938973Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Pre - processing the test dataset ##","metadata":{}},{"cell_type":"code","source":"# Check for missing values\n\ntest_df[test_df.isnull().any(axis = 1)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:57:32.940292Z","iopub.execute_input":"2025-09-23T10:57:32.940524Z","iopub.status.idle":"2025-09-23T10:57:32.971094Z","shell.execute_reply.started":"2025-09-23T10:57:32.940508Z","shell.execute_reply":"2025-09-23T10:57:32.970195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize distribution of labels using countplot\n\nplt.figure(figsize = (3, 5))\nax = sns.countplot(x = 'LABEL', data = test_df)\nax.bar_label(ax.containers[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:57:32.971964Z","iopub.execute_input":"2025-09-23T10:57:32.972272Z","iopub.status.idle":"2025-09-23T10:57:33.096266Z","shell.execute_reply.started":"2025-09-23T10:57:32.972246Z","shell.execute_reply":"2025-09-23T10:57:33.095390Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replacing the labels 2 and 1 with 1 and 0 respectively\ntest_df = test_df.replace({\"LABEL\": {2 : 1, 1 : 0}})\ntest_df.LABEL.unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:57:33.097071Z","iopub.execute_input":"2025-09-23T10:57:33.097291Z","iopub.status.idle":"2025-09-23T10:57:33.113159Z","shell.execute_reply.started":"2025-09-23T10:57:33.097274Z","shell.execute_reply":"2025-09-23T10:57:33.112168Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Handle outliers\n\nplt.figure(figsize = (20, 9))\nfor i in range(1, 4):\n    plt.subplot(1, 4, i)\n    sns.boxplot(data = test_df, x = 'LABEL', y = 'FLUX.' + str(i))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:57:33.114181Z","iopub.execute_input":"2025-09-23T10:57:33.114532Z","iopub.status.idle":"2025-09-23T10:57:33.528028Z","shell.execute_reply.started":"2025-09-23T10:57:33.114503Z","shell.execute_reply":"2025-09-23T10:57:33.527143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.drop(test_df[test_df['FLUX.2'] > 0.25e6].index, axis = 0, inplace = True)\nsns.boxplot(data = test_df, x = 'LABEL', y = 'FLUX.' + str(np.random.randint(1000)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:57:33.529027Z","iopub.execute_input":"2025-09-23T10:57:33.529271Z","iopub.status.idle":"2025-09-23T10:57:33.678244Z","shell.execute_reply.started":"2025-09-23T10:57:33.529252Z","shell.execute_reply":"2025-09-23T10:57:33.677373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract features and labels\n\nx_unseen = test_df.drop(['LABEL'], axis = 1)\ny_unseen = test_df.LABEL\nx_unseen, y_unseen","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:57:33.679177Z","iopub.execute_input":"2025-09-23T10:57:33.679456Z","iopub.status.idle":"2025-09-23T10:57:33.701149Z","shell.execute_reply.started":"2025-09-23T10:57:33.679424Z","shell.execute_reply":"2025-09-23T10:57:33.700370Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Feature scaling\n\nx_unseen_sc = sc.fit_transform(x_unseen)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:57:33.702040Z","iopub.execute_input":"2025-09-23T10:57:33.702859Z","iopub.status.idle":"2025-09-23T10:57:33.771480Z","shell.execute_reply.started":"2025-09-23T10:57:33.702828Z","shell.execute_reply":"2025-09-23T10:57:33.770713Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict the labels for the scaled test set\ny_pred = knn_classifier.predict(x_unseen_sc)\n\n# Results\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, auc\n\nprint(\"Validation accuracy of KNN: \", accuracy_score(y_unseen, y_pred))\nprint()\nprint(\"Classification report: \\n\", classification_report(y_unseen, y_pred))\n\n# Confusion matrix\nplt.figure(figsize = (15,11))\nplt.subplots_adjust(wspace = 0.3)\nplt.suptitle(\"KNN Performance before handling the imbalance in data\", color = 'b', weight = 'bold')\nplt.subplot(221)\nsns.heatmap(confusion_matrix(y_unseen, y_pred), annot = True, cmap = \"Set2\", fmt = \"d\", linewidths = 3, cbar = False, xticklabels = ['Non - exoplanet', 'Exoplanet'], yticklabels = ['Non - exoplanet', 'Exoplanet'], square = True)\nplt.xlabel(\"Actual Labels\", fontsize = 15, weight = 'bold', color = 'tab:pink')\nplt.ylabel(\"Predicted Labels\", fontsize = 15, weight = 'bold', color = 'tab:pink')\nplt.title(\"Confusion Matrix\", fontsize = 20, color = 'm')\n\n# ROC Curve and Area under the curve\npredicting_probabilities = knn_classifier.predict_proba(x_unseen_sc)[:,1]\nfpr, tpr, thresholds = roc_curve(y_unseen, predicting_probabilities)\nplt.subplot(222)\nplt.plot(fpr, tpr, label = (\"AUC: \", auc(fpr, tpr)), color = 'g')\nplt.plot([1,0], [1,0], \"k--\")\nplt.legend()\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC - Curve and Area under the curve\", fontsize = 20, color = 'm')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T10:57:33.772332Z","iopub.execute_input":"2025-09-23T10:57:33.772587Z","iopub.status.idle":"2025-09-23T10:57:35.212558Z","shell.execute_reply.started":"2025-09-23T10:57:33.772569Z","shell.execute_reply":"2025-09-23T10:57:35.211604Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As we can observe, due to the test dataset being higly imbalanced as well, the model did not make any predictions for exoplanet, i.e., the true positives are zero.","metadata":{}}]}